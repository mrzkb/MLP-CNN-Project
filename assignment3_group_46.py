# -*- coding: utf-8 -*-
"""assignment3_group-46.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p4RTCYjHpFqW4cZLaOJkMVOUNOW8SrhR

# **Task 1: Acquire the data**
"""

import numpy as np
import pandas as pd
import sys
import os

import keras
from keras.models import Sequential
from keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

#Run this line once, to change the directory to your drive
os.chdir('drive/MyDrive')

#'sign_mnist_train.csv' and 'sign_mnist_test.csv' should be put under /content/drive/MyDrive
!pwd
!ls

"""The dataset format is patterned to match closely with the classic MNIST. Each training and test case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because of gesture motions). The training data (**27,455 cases**) and test data (**7172 cases**) are approximately half the size of the standard MNIST handwritten digit dataset but otherwise similar with a header row of label, **pixel1,pixel2â€¦.pixel784** which represent a single 28x28 pixel image with grayscale values between **0-255**."""

train_df=pd.read_csv('sign_mnist_train.csv')
test_df=pd.read_csv('sign_mnist_test.csv')

train_df.info()

test_df.info()

train_df.describe()

train_df.head(6)

"""We will now see how the distribution of the classes in the training set."""

df = pd.DataFrame(train_df['label'])
df.rename(columns={'label': 'Letters'}, inplace=True)
sns.catplot(data =df, x='Letters', kind="count", palette='deep', width=0.9)

"""The classes are uniformly distributed in the training set.
Let's do the same with the test set.
"""

df = pd.DataFrame(test_df['label'])
df.rename(columns={'label': 'Letters'}, inplace=True)
sns.catplot(data =df, x='Letters', kind="count", palette='deep', width=0.9)

"""Slightly less uniform.

Dropping 1st column of train set which is the label column.
"""

train_label=train_df['label']
train_label.head()
trainset=train_df.drop(['label'],axis=1)
trainset.head()
#print(train_label)

"""Converting the dataframe to numpy array type to be used while training the CNN. The array is converted from 1-D to **3-D** which is the required input to the first layer of the CNN. Similar preprocessing is done to the test dataframe. *Can remove that later or keep it*"""

X_train = trainset.values
#X_train = trainset.values.reshape(-1,28,28,1)
print(X_train.shape)

"""Dropping 1st column of test set which is the label column."""

test_label=test_df['label']
X_test=test_df.drop(['label'],axis=1)
print(X_test.shape)
X_test.head()

"""Binarizing the train and test label to an array of size 24"""

from sklearn.preprocessing import LabelBinarizer
lb=LabelBinarizer()
y_train=lb.fit_transform(train_label)
y_test=lb.fit_transform(test_label)

y_train

"""Converting the dataframe to numpy array type to be used while training the CNN. The array is converted from 1-D to **3-D** which is the required input to the first layer of the CNN. Similar preprocessing is done to the test dataframe. *Can remove that later or keep it*"""

#For CNN
#X_test=X_test.values.reshape(-1,28,28,1)

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

"""Standardizing the test and train data"""

X_train = X_train.astype(np.float64)
X_train -= np.mean(X_train, axis = 0)
X_train /= np.std(X_train, axis = 0)

X_test = X_test.astype(np.float64)
X_test -= np.mean(X_test, axis = 0)
X_test /= np.std(X_test, axis = 0)
X_test = np.array(X_test)

"""Normalizing Test and train data"""

#Normalizing both train and test sets so that each pixel is between [0,1]
#X_train = X_train / 255
#X_test = X_test / 255
#X_test = np.array(X_test)

fig,axe=plt.subplots(2,2)
fig.suptitle('Preview of dataset')
axe[0,0].imshow(X_train[0].reshape(28,28),cmap='gray')
axe[0,0].set_title('label: 3  letter: C')
axe[0,1].imshow(X_train[1].reshape(28,28),cmap='gray')
axe[0,1].set_title('label: 6  letter: F')
axe[1,0].imshow(X_train[2].reshape(28,28),cmap='gray')
axe[1,0].set_title('label: 2  letter: B')
axe[1,1].imshow(X_train[4].reshape(28,28),cmap='gray')
axe[1,1].set_title('label: 13  letter: M')

"""# **Task 2: Implementing an MLP to classify image data**"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
from IPython.core.debugger import set_trace
import warnings
warnings.filterwarnings('ignore')
import math
import numpy as np

from typing import List
from tqdm import tqdm

class NeuralNetLayer:
    def __init__(self):
        self.gradient = None
        self.parameters = None

    def forward(self, x):
        raise NotImplementedError

    def backward(self, gradient):
        raise NotImplementedError

class LinearLayer(NeuralNetLayer):
    def __init__(self, input_size, output_size):
        super().__init__()
        self.ni = input_size
        self.no = output_size

        #Weight initialization
        self.w = np.random.randn(output_size, input_size) / 100
        self.b = np.random.randn(output_size) / 100

        self.cur_input = None
        self.parameters = [self.w, self.b]

    def forward(self, x):

      self.cur_input = np.clip(x, -sys.float_info.max, sys.float_info.max)

      temp = (self.w[None, :, :] @ self.cur_input[:, :, None])[:,:,0] + self.b

      #If overflow occurs
      temp = np.clip(temp, -sys.float_info.max, sys.float_info.max)
      if np.isnan(temp).any():
        print("\n NaN in Linear Layer")

      return temp

    def backward(self, gradient):
        assert self.cur_input is not None, "Must call forward before backward"
        dw = gradient.T.dot(self.cur_input) / gradient.shape[0]  #divide by batch size so that our gradients remain not too large
        db = gradient.mean(axis = 0) #same thing here take the mean
        self.gradient = [dw, db]
        return gradient.dot(self.w)

class ReLULayer(NeuralNetLayer):
    def __init__(self):
        super().__init__()

    def forward(self, x):
        self.gradient = np.where(x > 0, 1.0, 0.0)
        return np.maximum(0, x)

    def backward(self, gradient):
        assert self.gradient is not None, "Must call forward before backward"
        return gradient * self.gradient

class SigmoidLayer(NeuralNetLayer):
    def __init__(self):
        super().__init__()

    def forward(self, x):
        sig = (1 / (1 + np.exp(-x)))
        self.gradient = sig *  (1 - sig)
        return sig

    def backward(self, gradient):
        assert self.gradient is not None, "Must call forward before backward"
        return gradient * self.gradient

class LeakyReLULayer(NeuralNetLayer):
    def __init__(self, delta):
        super().__init__()
        self.delta = delta

    def forward(self, x):
        self.gradient = np.where(x > 0, 1.0, self.delta)
        return np.maximum(0, x) + self.delta * np.minimum(0,x)

    def backward(self, gradient):
        assert self.gradient is not None, "Must call forward before backward"
        return gradient * self.gradient

class SoftmaxOutputLayer(NeuralNetLayer):
    def __init__(self):
        super().__init__()
        self.cur_probs = None

    def forward(self, x):
        exps = np.exp(x)

        #Clips the values so that we don't get Inf / Inf in the line below
        exps = np.clip(exps, -sys.float_info.max, sys.float_info.max)

        probs = exps / np.sum(exps, axis=-1)[:, None]
        self.cur_probs = probs
        return probs

    def backward(self, target):
        assert self.cur_probs is not None, "Must call forward before backward"
        return self.cur_probs - target

"""class Optimizer from NumpyDeepMLP"""

#Run MLP class cell (next cell) before running this cell
class Optimizer:
    def __init__(self, net: MLP):
        self.net = net

    def step(self):
        for layer in self.net.layers[::-1]:
            if layer.parameters is not None:
                self.update(layer.parameters, layer.gradient)

    def update(self, params, gradient):
        raise NotImplementedError

class GradientDescentOptimizer(Optimizer):
    def __init__(self, net: MLP, lr: float, l2_lambda = None):
        super().__init__(net)
        self.lr = lr
        self.l2_lambda = l2_lambda

    def update(self, params, gradient):
        for (p, g) in zip(params, gradient):
          if (self.l2_lambda is None):
            p -= self.lr * g
          else:
            # adding L2 regularization
            p -= self.lr * (g + self.l2_lambda * p)

"""MLP class"""

'''
activation_function is the activation function that we'll use at every layer
an example activation function would be activation_function = "ReLU"
Please select an activation function from the list: "ReLU", "Sigmoid" and "LeakyReLU"

num_hidden is the number of hidden layers of the MLP (integer)
num_units is the number of units for each layer (num_units is a np vector of length = num_hidden)
num_features is the number of features in our dataset
num_output_classes is the number of output classes in our test data
'''

class MLP:
    def __init__(self, activation_function, num_hidden, num_units, num_features, num_output_classes):

        generate_layers = []

        if (num_hidden == 0):
          #if no hidden layers
            input_size = num_features
            output_size = num_output_classes

            generate_layers.append(LinearLayer(input_size, output_size))
            generate_layers.append(SoftmaxOutputLayer())

        else:
            # initialize the hidden layers
            for i in range(num_hidden):

                if (i == 0):
                    input_size = num_features
                else:
                    input_size = num_units[i - 1]

                output_size = num_units[i]

                generate_layers.append(LinearLayer(input_size, output_size))

                if (activation_function == "ReLU"):
                    generate_layers.append(ReLULayer())
                elif (activation_function == "Sigmoid"):
                    generate_layers.append(SigmoidLayer())
                elif (activation_function == "LeakyReLU"):
                    generate_layers.append(LeakyReLULayer(0.1)) #delta = 0.1, can change that manually
                else:
                    print("Error: invalid activation function passed as argument to MLP constructor")
                    print("Please select an activation function from: 'ReLU'', 'Sigmoid' and 'LeakyReLU'")

            # initialize the output layer
            input_size = num_units[num_hidden - 1]
            output_size = num_output_classes

            generate_layers.append(LinearLayer(input_size, output_size)) #input layer
            generate_layers.append(SoftmaxOutputLayer()) #output layer

        self.layers = generate_layers

    def forward(self, x):
        for layer in self.layers:
            x = layer.forward(x)
        return x

    def backward(self, target):
        for layer in self.layers[::-1]:
            target = layer.backward(target)

    def fit_mini_batch(self, x, y, learning_rate, epoch, batch_size, validation_data = None, validation_label= None, validation_stop = None, save_fig = None, l2_lambda = None):
      '''
      validation_data and validation_label are the validation sets to stop the descent, the stopping criteria takes the mean over the past validation_stop
      validation loss. Save_fig is to plot and show the convergence graph.
      '''
      optimizer = GradientDescentOptimizer(self, learning_rate, l2_lambda)
      losses = []
      validation_losses = []
      labels = np.array(y)
      flag = False #indicator to stop the descent

      for _ in tqdm(range(epoch)):
        if(flag):
          break
        for i in range(x.shape[0] // batch_size + 1):
          if (i + 1) *  batch_size > x.shape[0] :
            xi = x[i * batch_size : x.shape[0]]
            yi = labels[i * batch_size : labels.shape[0]]
          else:
            xi = x[i * batch_size : (i + 1) * batch_size]
            yi = labels[i * batch_size : (i + 1) * batch_size]
          predictions = self.forward(xi)

          loss = -(yi * np.log(predictions + sys.float_info.min)).sum(axis = -1).mean()
          losses.append(loss)

          self.backward(yi)
          optimizer.step()

          #Below we check if validation loss increases over the past # validation_stop past average loss
          if (validation_data is not None):
            validation_prediction = self.predict(validation_data)
            valid_loss = -(validation_label * np.log(validation_prediction + sys.float_info.min)).sum(axis = -1).mean()
            if (i > validation_stop and np.mean(validation_losses[i - validation_stop - 1: i-1]) < valid_loss):
              print("Validation loss increased afer iteration:", i)
              flag = True
              break
            else:
               validation_losses.append(valid_loss)

      if save_fig is not None:
        plt.plot(losses, color = 'red', label = 'Training Entropy')
        plt.plot(validation_losses, color = 'blue', label = 'Validation Entropy')
        plt.xlabel("Epoch")
        plt.ylabel("Cross entropy loss")
        plt.legend()
        plt.title(save_fig)
        plt.savefig(save_fig + '.png')

    def predict(self, x):
      return self.forward(x)

     #to check gradient with numerical approximation
    def check_grad(self, X, target):
      derived_grad_w = []
      derived_grad_b = []
      numerical_grad_w = []
      numerical_grad_b = []

      #update the gradients with the current input x
      self.forward(X)
      self.backward(target)

      for layer in self.layers[::-1]:
        if(isinstance(layer, LinearLayer)):
          derived_grad_w.append(layer.gradient[0]) #weights
          derived_grad_b.append(layer.gradient[1]) #biases

          epsilon = 1e-8 #epsilon; arbitrarily large value
          C,D = layer.parameters[0].shape
          epsilon_w = np.random.random((C, D)) * epsilon
          epsilon_b = np.random.random(C) * epsilon
          W = layer.w.copy()
          B = layer.b.copy()

          #Numerical gradients for weights
          layer.w = layer.w + epsilon_w
          J1 = -(target * np.log(self.forward(X) + sys.float_info.min)).sum(axis = -1).mean()
          layer.w = W

          layer.w = layer.w - epsilon_w
          J2 = -(target * np.log(self.forward(X) + sys.float_info.min)).sum(axis = -1).mean()
          layer.w = W

          numeric_grad_w = (J1 - J2) / (2 * epsilon_w)
          numerical_grad_w.append(numeric_grad_w)

          #Numerical gradients for Biases
          layer.b = layer.b + epsilon_b
          J1 = -(target * np.log(self.forward(X) + sys.float_info.min)).sum(axis = -1).mean()
          layer.b = B

          layer.b = layer.b - epsilon_b
          J2 = -(target * np.log(self.forward(X) + sys.float_info.min)).sum(axis = -1).mean()
          layer.b = B

          numeric_grad_b = (J1 - J2) / (2 * epsilon_b)
          numerical_grad_b.append(numeric_grad_b)

      return derived_grad_w, numerical_grad_w, derived_grad_b, numerical_grad_b

"""Our evaluate_acc function"""

def evaluate_acc(y, y_pred):
    accuracy = sum(y_pred.argmax(axis=1) == y.argmax(axis=1))
    accuracy = accuracy / y.shape[0]
    return accuracy

"""### Checking Gradients With numerical approximations"""

#Two hidden layer
NUM_UNITS_TO_TEST = 256
num_hidden = 2
num_units = [NUM_UNITS_TO_TEST, NUM_UNITS_TO_TEST]
num_features = X_train.shape[1]
num_output_classes = 24
learning_rate = 0.01
epoch = 1

mlp = MLP("LeakyReLU", num_hidden, num_units, num_features, num_output_classes)
#mlp.fit_mini_batch(X_train[0:500], y_train[0:500], learning_rate, epoch, 1000)

derived_grad_w, numerical_grad_w, derived_grad_b, numerical_grad_b = mlp.check_grad(X_train[0:500], y_train[0:500] )

mse_w =[]
mse_b = []
for i in range(len(derived_grad_w) ):
  mse_w.append(np.square(derived_grad_w[i] - numerical_grad_w[i]).sum()  / (derived_grad_w[i].shape[0] * derived_grad_w[i].shape[1]))
  mse_b.append(np.square(derived_grad_b[i] - numerical_grad_b[i]).sum() / derived_grad_b[i].shape[0] )

index = index=['Output Layer','Layer 2','Layer 1']
mse_w = pd.DataFrame(mse_w, columns=['Weights Error'])
mse_b = pd.DataFrame(mse_b, columns=['Biases Error'])
concatenated = pd.concat([mse_w, mse_b], axis=1)
concatenated.index = index
title = "Mean Square error between Numerical Gradients and Derived Gradients for a two-layer model"
display(concatenated.style.set_caption(title))

"""# **Task 3: Running the experiments**"""

from sklearn import model_selection
#Spliting data into train and validation data

#Taking a subset of the training data
X_train_split, X_valid_train, y_train_split, y_valid_train = model_selection.train_test_split(X_train, y_train, test_size = 0.1, random_state=1, shuffle=True)

#Taking a subset of the test data
X_test_split, X_valid_test, y_test_split, y_valid_test = model_selection.train_test_split(X_test, y_test, test_size = 0.15, random_state=1, shuffle=True)

X_valid = np.append(X_valid_test, X_valid_train, axis = 0)
y_valid = np.append(y_valid_test, y_valid_train, axis = 0)

print(X_train.shape)
print(X_test.shape)

"""##Experiment 1

Create three different models: (1) an MLP with **no hidden layer**, i.e., it directly maps the inputs to outputs (Hint: you may find some of your code for Assignment 2 comes in handy for this one), (2) an MLP with a **single hidden layer** having **ReLU activations**, (3) an MLP with **2 hidden layers** having **ReLU activations**.

Start by hyperparameter tuning the MLP with no hidden layers (multi-class)
"""

#No hidden layer so all we will be testing is the learning rate
num_hidden = 0
num_units = []
epoch=2
num_features = X_train.shape[1]
learning_rates= [0.1, 0.05, 0.01, 0.005]  #learning rates to test

lr_and_accuracies={}
accuracies_and_lr={}
for rate in learning_rates:
  mlp1 = MLP("ReLU", 0, num_units, num_features, num_output_classes)
  mlp1.fit_mini_batch(X_train_split, y_train_split, rate, epoch, 64) #X_valid, y_valid, 30
  y_pred1 = mlp1.predict(X_valid)
  y_train_pred = mlp1.predict(X_train)
  acc1 = evaluate_acc(y_pred1, y_valid)
  acc_train_1 = evaluate_acc(y_train_pred, y_train)

  lr_and_accuracies.update({acc1: rate})
  accuracies_and_lr.update({rate: [acc_train_1,acc1]})

  print('********************* MLP with 0 hidden layers and 2 epochs *********************')
  print('Learning Rate:', rate)
  print("Training accuracy: ", acc_train_1)
  print("Validation accuracy: ", acc1)
  print("\n")

accuracy1=np.max(list(lr_and_accuracies.keys()))
print('********************************************************************************************************************************')
print('The best validation accuracy for MLP with 0 hidden layers and 2 epochs is', accuracy1, 'with a learning rate of', lr_and_accuracies[accuracy1] )

df = pd.DataFrame.from_dict(accuracies_and_lr, orient='index', columns=['Train Accuracy', 'Validation Accuracy'])
df.index.name = 'Rate'

title = "Learning rate vs train vs validation accuracy for 0-layer MLP"

display(df.style.set_caption(title).set_table_styles([{'selector': 'caption', 'props': [('text-align', 'center')]}]))

#now we can run our 0 layer MLP on the test data
mlp1 = MLP("ReLU", 0, num_units, num_features, num_output_classes)
mlp1.fit_mini_batch(X_train_split, y_train_split, lr_and_accuracies[accuracy1], 10, 64) #, X_valid, y_valid, 30,'Gradient Descent With 64 Batch Size of The MLP \n With Zero Hidden Layer After Hyperparameter Tunning'

y_test_pred1 = mlp1.predict(X_test_split)
accuracy_test1 = evaluate_acc(y_test_pred1, y_test_split)
print(accuracy_test1)

"""Our 0 layer MLP gives us 68% accuracy on test

Next we tune the model with one hidden layer
"""

#Hyperparameter tuning of model with one hidden layer
NUM_UNITS_TO_TEST = [32, 64, 128, 256]
num_hidden = 1
num_features = X_train.shape[1]
num_output_classes = 24
epoch = 2
learning_rates= [0.1, 0.05, 0.01, 0.005]    #learning rates to test
lr_units_accuracies={}
train_accuracy_list=[]
validation_accuracy_list=[]

for units in NUM_UNITS_TO_TEST:
  units=[units] * 1
  for rate in learning_rates:

    mlp2 = MLP("ReLU", num_hidden, units, num_features, num_output_classes)
    mlp2.fit_mini_batch(X_train_split, y_train_split, rate, epoch, 64) #, X_valid, y_valid, 30
    y_train_pred2 = mlp2.predict(X_train_split)
    y_valid_pred2 = mlp2.predict(X_valid)
    acc_train2 = evaluate_acc(y_train_pred2, y_train_split)
    acc2 = evaluate_acc(y_valid_pred2, y_valid)

    lr_units_accuracies.update({acc2:[units,rate]})
    train_accuracy_list.append(acc_train2)
    validation_accuracy_list.append(acc2)


    print('********************* MLP with 1 hidden layer and 2 epochs *********************')
    print('Units per layer:', units)
    print('Learning Rate:', rate)
    print("Training accuracy: ", acc_train2)
    print("Validation accuracy: ", acc2)
    print("\n")

accuracy2=np.max(list(lr_units_accuracies.keys()))
print('********************************************************************************************************************************')
print('The best validation accuracy for MLP with 1 hidden layer and 2 epochs is', accuracy2, 'with a learning rate of', lr_units_accuracies[accuracy2][1],'\n and ', lr_units_accuracies[accuracy2][0], 'units per layer.')

#mlp2 = MLP("ReLU", num_hidden, num_units, num_features, num_output_classes)
#mlp2.fit_mini_batch(X_train_split, y_train_split, learning_rate, epoch, 64, X_valid , y_valid, 25)

accuracies = [
    [validation_accuracy_list[0], validation_accuracy_list[1], validation_accuracy_list[2], validation_accuracy_list[3]],
    [validation_accuracy_list[4], validation_accuracy_list[5], validation_accuracy_list[6], validation_accuracy_list[7]],
    [validation_accuracy_list[8], validation_accuracy_list[9], validation_accuracy_list[10], validation_accuracy_list[11]],
    [validation_accuracy_list[12],validation_accuracy_list[13],validation_accuracy_list[14],validation_accuracy_list[15]]
]
transposed_accuracies = list(zip(*accuracies))

units=NUM_UNITS_TO_TEST
rates=learning_rates

import pandas as pd

# Assuming `rates` and `units` are defined
rates = learning_rates
units = NUM_UNITS_TO_TEST

# Create a DataFrame
MLP1_df = pd.DataFrame(transposed_accuracies, index=rates, columns=units)

title = "Validation accuracies at each Unit and Learning rate for 1-layer MLP"

display(MLP1_df.style.set_caption(title).set_table_styles([{'selector': 'caption', 'props': [('text-align', 'center')]}]))

#now we can run our 1 layer MLP on the test data with the best hyperparameters found on validation
mlp2 = MLP("ReLU", 1, lr_units_accuracies[accuracy2][0], num_features, num_output_classes)

mlp2.fit_mini_batch(X_train_split, y_train_split, lr_units_accuracies[accuracy2][1], 15, 64) # X_valid, y_valid, 50, 'Gradient Descent With 64 Batch Size of The MLP \n With One Hidden Layer After Hyperparameter Tunning'
y_test_pred2 = mlp2.predict(X_test_split)
accuracy_test2 = evaluate_acc(y_test_pred2, y_test_split)
print(accuracy_test2)

"""On test we get 79% accuracy with the tuned model

Finally tune the model with 2 hidden layers
"""

#Hyperparameter tuning of model with two hidden layers
NUM_UNITS_TO_TEST = [32, 64, 128, 256]
num_hidden = 2
num_features = X_train.shape[1]
num_output_classes = 24
epoch = 2
learning_rates= [0.1, 0.05, 0.01, 0.005]    #learning rates to test
lr_units_accuracies2={}
validation_accuracy_list1=[]

for units in NUM_UNITS_TO_TEST:
  units=[units] * 2
  for rate in learning_rates:

    mlp3 = MLP("ReLU",num_hidden, units, num_features, num_output_classes)
    mlp3.fit_mini_batch(X_train_split, y_train_split, rate, epoch, 64) #, X_valid, y_valid, 25
    y_valid_pred3 = mlp3.predict(X_valid)
    y_train_pred = mlp3.predict(X_train_split)
    acc3 = evaluate_acc(y_valid_pred3, y_valid)
    acc_train3 = evaluate_acc(y_train_pred, y_train_split)

    lr_units_accuracies2.update({acc3:[units,rate]})
    validation_accuracy_list1.append(acc3)

    print('********************* MLP with 2 hidden layers and 2 epochs *********************')
    print('Units per layer:', units)
    print('Learning Rate:', rate)
    print("Training accuracy: ", acc_train3)
    print("Validation accuracy: ", acc3)
    print("\n")

accuracy=np.max(list(lr_units_accuracies2.keys()))
print('********************************************************************************************************************************')
print('The best validation accuracy for MLP with 2 hidden layers and 2 epochs is', accuracy, 'with a learning rate of', lr_units_accuracies2[accuracy][1],'\n and ', lr_units_accuracies2[accuracy][0], 'units per layer.')

accuracy=np.max(list(lr_units_accuracies2.keys()))
print(accuracy)
print(lr_units_accuracies2[accuracy])

accuracies1 = [
    [validation_accuracy_list1[0], validation_accuracy_list1[1], validation_accuracy_list1[2], validation_accuracy_list1[3]],
    [validation_accuracy_list1[4], validation_accuracy_list1[5], validation_accuracy_list1[6], validation_accuracy_list1[7]],
    [validation_accuracy_list1[8], validation_accuracy_list1[9], validation_accuracy_list1[10], validation_accuracy_list1[11]],
    [validation_accuracy_list1[12],validation_accuracy_list1[13],validation_accuracy_list1[14],validation_accuracy_list1[15]]
]
transposed_accuracies1 = list(zip(*accuracies1))

units=NUM_UNITS_TO_TEST
rates=learning_rates

# Assuming `rates` and `units` are defined
rates = learning_rates
units = NUM_UNITS_TO_TEST

# Create a DataFrame
MLP2_df = pd.DataFrame(transposed_accuracies1, index=rates, columns=units)

title = "Validation accuracies at each Unit and Learning rate for 2-layer MLP"

display(MLP2_df.style.set_caption(title).set_table_styles([{'selector': 'caption', 'props': [('text-align', 'center')]}]))

#now we can run our 2 layer MLP on the test data with the best hyperparameters found on validation
#mlp3 = MLP("ReLU",num_hidden,units,num_features,num_output_classes)
mlp3 = MLP("ReLU", 2, lr_units_accuracies2[accuracy][0], num_features, num_output_classes)
mlp3.fit_mini_batch(X_train_split, y_train_split, lr_units_accuracies2[accuracy][1], 15, 64) #X_valid, y_valid, 25, 'Gradient Descent With 64 Batch Size of The MLP \n With Two Hidden Layer After Hyperparameter Tunning'

y_train_pred3 = mlp3.predict(X_train_split)
y_test_pred3 = mlp3.predict(X_test_split)
accuracy_test3 = evaluate_acc(y_test_pred3, y_test_split)
accuracy_train_3=evaluate_acc(y_train_pred3, y_train_split)

print('The test accuracy of the tuned 2-layer MLP is:', accuracy_test3)

#3 models and 3 accuracies make a bar plot

MLP_accuracies = [accuracy_test1, accuracy_test2, accuracy_test3]
MLP_names = ['0-layer MLP', '1-layer MLP', '2-layer MLP']

plt.figure(figsize=(10, 6))
plt.bar(MLP_names, MLP_accuracies, color='skyblue')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Accuracy of MLP Models')
plt.ylim(0, 1)  # Setting y-axis limits to be between 0 and 1
plt.show()

"""##Experiment 2

Take the last model above, i.e., the one with 2 hidden layers, and create two different copies of it in which the activation functions are now **sigmoid** and **Leaky-ReLU**.

We now test two other 2-layer MLPs, with the same hyperparameters that gave us the best accuracy for our MLP with ReLU activation.
The difference between these models and the one we just tuned is these models use LeakyReLU or Sigmoid activation functions instead of ReLU.
"""

num_units = [256,256]
epoch = 15
learning_rate = 0.1

#leaky_MLP1 = MLP("LeakyReLU", 1, num_units, num_features, num_output_classes)
#sigmoid_MLP1 = MLP("Sigmoid", 1, num_units, num_features, num_output_classes)

leaky_MLP2 = MLP("LeakyReLU", 2, num_units, num_features, num_output_classes)
sigmoid_MLP2 = MLP("Sigmoid", 2, num_units, num_features, num_output_classes)

'''
#stats for sigmoid 1 layer
sigmoid_MLP1.fit_mini_batch(X_train_split, y_train_split, learning_rate, epoch, 64, X_valid, y_valid, 30, 'Gradient Descent With 64 Batch Size of The MLP \n With One Hidden Layer Using Sigmoid Activation Function')
sigmoid_y_pred1 = sigmoid_MLP1.predict(X_test_split)
sigmoid_y_train_pred1 = sigmoid_MLP1.predict(X_train_split)
sigmoid_acc1 = evaluate_acc(sigmoid_y_pred1, y_test_split)
sigmoid_acc_train1 = evaluate_acc(sigmoid_y_train_pred1, y_train_split)

#stats for LeakyReLU 1 layer
leaky_MLP1.fit_mini_batch(X_train_split, y_train_split, learning_rate, epoch, 64, X_valid , y_valid, 30, 'Gradient Descent With 64 Batch Size of The MLP \n With One Hidden Layer Using LeakyReLU Activation Function')
leaky_y_pred1 = leaky_MLP1.predict(X_test_split)
leaky_y_train_pred1 = leaky_MLP1.predict(X_train_split)
leaky_acc1 = evaluate_acc(leaky_y_pred1, y_test_split)
leaky_acc_train1 = evaluate_acc(leaky_y_train_pred1, y_train_split)
'''
#stats for sigmoid 2 layer
sigmoid_MLP2.fit_mini_batch(X_train_split, y_train_split, learning_rate, epoch, 64) #, X_valid, y_valid, 30, 'Gradient Descent With 64 Batch Size of The MLP \n With Two Hidden Layers Using Sigmoid Activation Function'
sigmoid_y_pred2= sigmoid_MLP2.predict(X_test_split)
sigmoid_y_train_pred2 = sigmoid_MLP2.predict(X_train_split)
sigmoid_acc2= evaluate_acc(sigmoid_y_pred2, y_test_split)
sigmoid_acc_train2 = evaluate_acc(sigmoid_y_train_pred2, y_train_split)

#stats for LeakyReLU 1 layer
leaky_MLP2.fit_mini_batch(X_train_split, y_train_split, learning_rate, epoch, 64) #, X_valid , y_valid, 30, 'Gradient Descent With 64 Batch Size of The MLP \n With Two Hidden Layers Using LeakyReLU Activation Function'
leaky_y_pred2 = leaky_MLP2.predict(X_test_split)
leaky_y_train_pred2 = leaky_MLP2.predict(X_train_split)
leaky_acc2 = evaluate_acc(leaky_y_pred2, y_test_split)
leaky_acc_train2 = evaluate_acc(leaky_y_train_pred2, y_train_split)

'''
print("Sigmoid Test accuracy for 1 layer MLP: ", sigmoid_acc1)
print("Sigmoid Training accuracy for 1 lay MLP: ", sigmoid_acc_train1, "\n")

print("LeakyReLU Test accuracy for 1 layer MLP: ", leaky_acc1)
print("LeakyReLu Training accuracy for 1 layer MLP:: ", leaky_acc_train1, "\n")
'''
print("Sigmoid Test accuracy for 2 layer MLP: ", sigmoid_acc2)
print("Sigmoid Training accuracy for 2 layer MLP: ", sigmoid_acc_train2, "\n")

print("LeakyReLU Test accuracy for 2 layer MLP: ", leaky_acc2)
print("LeakyReLu Training accuracy for 2 layer MLP:: ", leaky_acc_train2, "\n")

models = ['ReLU', 'Sigmoid', 'LeakyReLU']

# Accuracy values
train_accuracy = [accuracy_train_3, sigmoid_acc_train2, leaky_acc_train2]
test_accuracy = [accuracy_test3, sigmoid_acc2, leaky_acc2]
#print(train_accuracy)
print(test_accuracy)
# Set the width of the bars
bar_width = 0.2

# Set the positions of the bars on the x-axis
r1 = np.arange(len(models))
r2 = [x + bar_width for x in r1]

# Plotting the bars
plt.bar(r1, train_accuracy, color='b', width=bar_width, edgecolor='grey', label='Train Accuracy')
plt.bar(r2, test_accuracy, color='r', width=bar_width, edgecolor='grey', label='Test Accuracy')

# Adding labels and title
plt.xlabel('Model', fontweight='bold')
plt.xticks([r + bar_width/2 for r in range(len(models))], models)
plt.ylabel('Accuracy', fontweight='bold')
plt.title('Train/Test Accuracy for 2-Layer MLP with Different Activation Functions', fontweight='bold')
plt.legend()

# Show plot
plt.grid(True)
plt.show()

"""## Experiment 3

For this experiment we'll compare the performance of our best 2-hidden layers mlp without L2 and our best 1-hidden layers mlp without L2 with our best 2-hidden layers mlp with L2 and our best 1-hidden layers mlp with L2 (respectively).

Our best 2-hidden layer MLP
"""

# best 2-hidden layer mlp
num_features = X_train.shape[1]
num_output_classes = 24
epochs = 5 # ?
best_lr = 0.1

# best 2-hidden layer model
print("Best 2-hidden layer model without L2")
best_mlp = MLP("ReLU", 2, [256,256], num_features, num_output_classes)
# train the model without L2
best_mlp.fit_mini_batch(X_train, y_train, best_lr, epochs, 64)
# compute the accuracy of that model
y_train_pred = best_mlp.predict(X_train)
y_test_pred = best_mlp.predict(X_test)
acc_train = evaluate_acc(y_train_pred, y_train)
acc_test = evaluate_acc(y_test_pred, y_test)
print("Training accuracy = " + str(acc_train))
print("Testing accuracy = " + str(acc_test))

# best 2-hidden layer model trained with L2
l2_lambda_list = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]

for i in range(len(l2_lambda_list)):
  l2_lambda = l2_lambda_list[i]
  print("Best 2-hidden layer model with L2")
  best_mlp = MLP("ReLU", 2, [256, 256], num_features, num_output_classes)
  best_mlp.fit_mini_batch(X_train, y_train, best_lr, epochs, 64, None, None, None, None, l2_lambda) # an extra parameter is passed to fit_mini_batch here
  # compute the accuracy of that model
  y_train_pred = best_mlp.predict(X_train)
  y_test_pred = best_mlp.predict(X_test)
  acc_train = evaluate_acc(y_train_pred, y_train)
  acc_test = evaluate_acc(y_test_pred, y_test)
  print("For lambda = " + str(l2_lambda) + " Training accuracy = " + str(acc_train))
  print("For lambda = " + str(l2_lambda) + " Testing accuracy = " + str(acc_test))

"""Additional investigation: Our best 1 hidden layer MLP"""

# best 1-hidden layer mlp
num_features = X_train.shape[1]
num_output_classes = 24
epochs = 5 # ?
best_lr = 0.1

# best 1-hidden layer model
print("Best 1-hidden layer model without L2")
best_mlp = MLP("ReLU", 1, [256], num_features, num_output_classes)
# train the model without L2
best_mlp.fit_mini_batch(X_train, y_train, best_lr, epochs, 64)
# compute the accuracy of that model
y_train_pred = best_mlp.predict(X_train)
y_test_pred = best_mlp.predict(X_test)
acc_train = evaluate_acc(y_train_pred, y_train)
acc_test = evaluate_acc(y_test_pred, y_test)
print("Training accuracy = " + str(acc_train))
print("Testing accuracy = " + str(acc_test))

# best 1-hidden layer model trained with L2
l2_lambda_list = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]

for i in range(len(l2_lambda_list)):
  l2_lambda = l2_lambda_list[i]
  print("Best 1-hidden layer model with L2")
  best_mlp = MLP("ReLU",1, [256], num_features, num_output_classes)
  best_mlp.fit_mini_batch(X_train, y_train, best_lr, epochs, 64, None, None, None, None, l2_lambda) # an extra parameter is passed to fit_mini_batch here
  # compute the accuracy of that model
  y_train_pred = best_mlp.predict(X_train)
  y_test_pred = best_mlp.predict(X_test)
  acc_train = evaluate_acc(y_train_pred, y_train)
  acc_test = evaluate_acc(y_test_pred, y_test)
  print("For lambda = " + str(l2_lambda) + " Training accuracy = " + str(acc_train))
  print("For lambda = " + str(l2_lambda) + " Testing accuracy = " + str(acc_test))

"""## Experiment 4"""

#import relevant libraries
import keras
import tensorflow
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.layers import BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import model_from_json
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPool2D, Dropout, MaxPooling2D, Activation, ZeroPadding2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam

#print(X_train.shape)
#rint(y_train.shape)
#print(X_test.shape)
#print(y_test.shape)

#format the input data for the CNN, I think the output labels don't need to be reshaped because the later layers of CNN are MLP
X_train_CNN = X_train.reshape(-1, 28, 28, 1)
X_test_CNN = X_test.reshape(-1, 28, 28, 1)
X_valid_CNN=X_valid.reshape(-1, 28, 28, 1)

print(X_train_CNN.shape)
print(X_test_CNN.shape)
print(X_valid_CNN.shape)
print(y_train.shape)
print(y_test.shape)

num_classes = 24
num_filters = 8
filter_size = 3
pool_size   = 2
batch_size  = 64
input_shape = (28, 28, 1)
strides     = 1
padding     = 'valid' # valid: no padding, same: for zeros evenly right/left and up/down.
                      # When padding="same" and strides=1, the output has the same size as the input

def create_CNN(num_units, num_filters, filter_size, strides, padding, learning_rate=0.001):
    model = Sequential()

    # Convolutional layers
    model.add(Conv2D(filters=num_filters,
                     kernel_size=filter_size,
                     strides=strides,
                     input_shape=input_shape,
                     padding=padding,
                     activation='relu'))

    model.add(Conv2D(filters=2 * num_filters,
                     kernel_size=filter_size,
                     strides=strides,
                     padding=padding,
                     activation='relu'))

    model.add(Conv2D(filters=4 * num_filters,
                     kernel_size=filter_size,
                     strides=strides,
                     padding=padding,
                     activation='relu'))
    model.add(MaxPooling2D(pool_size=pool_size))

    # Flatten layer
    model.add(Flatten())

    # Fully connected layers
    model.add(Dense(units=num_units, activation='relu'))
    model.add(Dense(units=num_units, activation='relu'))

    # Output layer
    model.add(Dense(units=num_classes, activation='softmax'))

    # Define optimizer with custom learning rate
    optimizer = Adam(learning_rate=learning_rate)

    # Compile the model with custom optimizer
    model.compile(optimizer=optimizer,
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    return model

#find best learning rate for our model
num_units=32
lr_results=[]
learning_rates= [0.1, 0.05, 0.01, 0.005, 0.001 ,0.0001]
for rate in learning_rates:
  cnn= create_CNN(num_units, num_filters, filter_size, strides, padding, learning_rate=rate)
  cnn.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
  valid_loss, valid_accuracy = cnn.evaluate(X_valid_CNN, y_valid)
  print(f"Valid accuracy with {rate} learning_rate: {valid_accuracy}")
  lr_results.append(valid_accuracy)

#a plot showing learning rate vs validation accuracy for our CNN
plt.plot(learning_rates, lr_results, marker='o')
plt.xscale('log')  # Set logarithmic scale for better visualization if learning rates vary widely
plt.xlabel('Learning Rate')
plt.ylabel('Validation Accuracy')
plt.title('Learning Rate vs. Validation Accuracy')
plt.grid(True)
plt.show()

num_hidden_units = [32, 64, 128, 256]
best=0.001
results=[]
# Train and evaluate models with different numbers of hidden layers
for num_units in num_hidden_units:
    cnn_model = create_CNN(num_units, num_filters, filter_size, strides, padding, learning_rate=best)
    cnn_model.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
    valid_loss, valid_accuracy = cnn_model.evaluate(X_valid_CNN, y_valid)
    print(f"Valid accuracy with {num_units} hidden units: {valid_accuracy}")
    results.append({'num_units': num_units, 'valid_accuracy': valid_accuracy})

num_units_list = [result['num_units'] for result in results]
valid_accuracy_list = [result['valid_accuracy'] for result in results]

# Plotting
plt.figure(figsize=(8, 6))
plt.plot(num_units_list, valid_accuracy_list, marker='o')
plt.title('Model Validation Accuracy vs Number of Hidden Units')
plt.xlabel('Number of Hidden Units')
plt.ylabel('Validation Accuracy')
plt.grid(True)
plt.xticks(num_units_list)  # Set x-axis ticks to the number of units
plt.show()

#varying hyperparameters to see if it changes our CNN accuracy.
#filter_size_testing=[2,4,6,8,10]
num_filter_testing=[2,5,7,10,15,18,22]
num_filters=8
accuracy_dict={}
CNN_accuracies=[]
num_units=256
'''
for filter_size in filter_size_testing:
  for num_filter in num_filter_testing:
    cnn_model = create_CNN(num_units, num_filters, filter_size, strides, padding)
    cnn_model.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
    test_loss, test_accuracy = cnn_model.evaluate(X_test_CNN, y_test)
    print(f"Test accuracy with filter size ={filter_size} and num_filters={num_filter}: {test_accuracy}")
    CNN_accuracies.append(test_accuracy)
    accuracy_dict.update({test_accuracy:[num_filters,filter_size]})

results_df = pd.DataFrame(results)
'''
for filter in num_filter_testing:
  cnn_model = create_CNN(num_units, filter, filter_size, strides, padding, learning_rate=best)
  cnn_model.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
  valid_loss, valid_accuracy = cnn_model.evaluate(X_valid_CNN, y_valid)
  print(f"Valid accuracy with num_filter ={filter}: {valid_accuracy}")
  CNN_accuracies.append(valid_accuracy)
  accuracy_dict.update({valid_accuracy:[num_filters,filter_size]})

cnn_model = create_CNN(num_units, 25, filter_size, strides, padding, learning_rate=best)
cnn_model.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
valid_loss, valid_accuracy = cnn_model.evaluate(X_valid_CNN, y_valid)

valid_accuracy_list = [result['valid_accuracy'] for result in results]

# Plotting
plt.figure(figsize=(8, 6))
plt.plot(num_filter_testing, CNN_accuracies, marker='o')
plt.title('CNN Validation Accuracy vs Number of filters')
plt.xlabel('Number of Filters')
plt.ylabel('Validation Accuracy')
plt.grid(True)
plt.xticks(num_filter_testing)
plt.show()

#finally putting it all together test CNN on test set
cnn_model = create_CNN(256, 22, filter_size, strides, padding, learning_rate=0.001)
cnn_model.fit(X_train_CNN, y_train, batch_size=64, epochs=2)
test_loss, test_accuracy = cnn_model.evaluate(X_test_CNN, y_test)
print('Test accuracy of tuned model is:',test_accuracy)

"""## Experiment 5

We start by analyzing the accuracy as a function of the **depth of the model**.
"""

#Start by testing the accuracy as a function of the depth of the model with 256 hidden units per layer
epoch= 5
num_features = X_train.shape[1]
rate = 0.1
depth = [1,2,3,4,5]
valid_accuracies = []

for i in depth:
  num_units = [256] * i
  mlp = MLP("ReLU", i, num_units, num_features, num_output_classes)
  mlp.fit_mini_batch(X_train_split, y_train_split, rate , epoch, 64)
  pred = mlp.predict(X_valid)
  valid_accuracy = evaluate_acc(pred, y_valid)
  print("Depth: ",i, "Validation accuracy: ", valid_accuracy)

"""We can observe that **deeper models are harder to converge**. We can try to make them converge by changing their activation function to **LeakyReLU** and giving them more epochs."""

#Train with 15 epochs
epoch= 8
num_features = X_train.shape[1]
rate = 0.10
depth = [3,4,5]
valid_accuracies = []

for i in depth:
  num_units = [256] * i
  mlp = MLP("LeakyReLU", i, num_units, num_features, num_output_classes)
  mlp.fit_mini_batch(X_train_split, y_train_split, rate , epoch, 64)
  pred = mlp.predict(X_valid)
  valid_accuracy = evaluate_acc(pred, y_valid)
  print("Depth: ",i, "Validation accuracy: ", valid_accuracy)

"""The model with depth 3 and 4 have converged, but even using a non-saturating activation function, the model with 5 layers has not converged. We can also notice that their validation accuracy is not better than shallow models. The **one-hidden layer** model gave the **best accuracy**, we will continue analysis testing with this model.

We will now try to increase the **width** of the model for 128, 256, 512, and 1,024 hidden units per layer.
"""

epoch= 8
num_features = X_train.shape[1]
rate = 0.10
num_units = [128]
num_hidden = 1
valid_accuracies = []
for i in range(4):
  mlp = MLP("ReLU", num_hidden, [num_units[0] * 2**i], num_features, num_output_classes)
  mlp.fit_mini_batch(X_train_split, y_train_split, rate , epoch, 64)
  pred = mlp.predict(X_valid)
  valid_accuracy = evaluate_acc(pred, y_valid)
  print("Width: ", num_units[0] * 2**i , "Validation accuracy: ", valid_accuracy)

"""The width of the model seems to have a positive influence on the accuracy. The model with **1,024 hidden units** gave the best validation accuracy. From experiment 2, we know that the **ReLU** activation function gave the best accuracy probably since our models were shallow. We will then keep this activation function. We can finally test the performance of this model using the test set."""

epoch= 8
num_features = X_train.shape[1]
rate = 0.10
num_units = [1024]
num_hidden = 1

mlp = MLP("ReLU", num_hidden, num_units, num_features, num_output_classes)
mlp.fit_mini_batch(X_train_split, y_train_split, rate , epoch, 64)
pred = mlp.predict(X_test_split)
test_accuracy = evaluate_acc(pred, y_test_split)
print(test_accuracy)

"""## Experiment 6"""

'''
the function expects MLP_model_list to be a list of MLPs with size >= 1

Assumptions:
training a model over 5 epochs is the same as training that model 5 times once
'''

import numpy as np
import matplotlib.pyplot as plt

def print_accuracy_curve(epoch, CNN_model, MLP_model_list, X_train, y_train, X_test, y_test, X_train_CNN, X_test_CNN):

  CNN_training_accuracies = []
  CNN_testing_accuracies = []

  number_of_mlps = len(MLP_model_list)

  #create a matrix where each row is the training accuracies of a different MLP model
  MLP_training_accuracies_matrix = np.zeros((number_of_mlps, epoch))

  #create a matrix where each row is the testing accuracies of a different MLP model
  MLP_testing_accuracies_matrix = np.zeros((number_of_mlps, epoch))

  for e in range(epoch):

    print("Epoch #" + str(e))

    # train CNN once
    CNN_model.fit(X_train_CNN, y_train, batch_size=64, epochs=1)

    # compute training accuracy
    training_loss, training_accuracy = cnn_model.evaluate(X_train_CNN, y_train)
    # store training accuracy in list
    CNN_training_accuracies.append(training_accuracy)

    # compute testing accuracy
    testing_loss, testing_accuracy = cnn_model.evaluate(X_test_CNN, y_test)
    # store testing accuracy in list
    CNN_testing_accuracies.append(testing_accuracy)

    for m in range(number_of_mlps):

      cur_mlp = MLP_model_list[m]

      #train MLP once (1 epoch)
      cur_mlp.fit_mini_batch(X_train, y_train, 0.1, 1, 64)

      #compute training accuracy
      y_pred_train = cur_mlp.predict(X_train)
      training_accuracy = evaluate_acc(y_train, y_pred_train)
      #store training accuracy in matrix
      MLP_training_accuracies_matrix[m][e] = training_accuracy
      # print("training acc: " + str(training_accuracy) + "after epoch " + str(1+e))

      #compute testing accuracy
      y_pred_test = cur_mlp.predict(X_test)
      testing_accuracy = evaluate_acc(y_test, y_pred_test)
      #store testing accuracy in matrix
      MLP_testing_accuracies_matrix[m][e] = testing_accuracy
      # print("testing acc: " + str(testing_accuracy) + "after epoch " + str(1+e))

  # plotting the CNN results
  plt.plot(CNN_training_accuracies, label='CNN training')
  plt.plot(CNN_testing_accuracies, label='CNN testing')

  # plotting the MLPs results

  for m in range(number_of_mlps):

    MLP_training_accuracies = []
    MLP_testing_accuracies = []

    for e in range(epoch):

      MLP_training_accuracies.append(MLP_training_accuracies_matrix[m][e])
      MLP_testing_accuracies.append(MLP_testing_accuracies_matrix[m][e])

    plt.plot(MLP_training_accuracies, label=str(m) + '-layer MLP training accuracy')
    plt.plot(MLP_testing_accuracies, label=str(m) + '-layer MLP testing accuracy')
  plt.ylim([0.3,1.05])
  plt.legend()
  plt.xlabel("Epoch")
  plt.ylabel("Accuracy")

# which models do you want to test?
num_units = [256]
num_features = X_train.shape[1]
num_output_classes = 24
learning_rate = 0.1
epochs=30

mlps=[]
mlp0= MLP("ReLU", 0, [], num_features, num_output_classes)
mlp1 = MLP("ReLU", 1, num_units, num_features, num_output_classes)
mlp2 = MLP("ReLU", 2, [256,256], num_features, num_output_classes)

mlps.append(mlp0)
mlps.append(mlp1)
mlps.append(mlp2)

num_units = 256
num_filters = 8
filter_size = 3
strides = 1
padding = 'valid'
cnn_model = create_CNN(num_units, num_filters, filter_size, strides, padding, 0.001)

print_accuracy_curve(epochs, cnn_model, mlps, X_train, y_train, X_test, y_test, X_train_CNN, X_test_CNN)